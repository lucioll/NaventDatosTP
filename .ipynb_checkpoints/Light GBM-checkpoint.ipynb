{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucio/Documentos/Datos/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/lucio/Documentos/Datos/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'sepostulo': np.dtype('uint8'),'edad': np.dtype('uint16')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "trainingSet = pd.read_csv('/home/lucio/Documentos/Datos/NaventDatosTP/Data/TRAINING_SET_SIN_ENCODING.csv',dtype=column_types)\n",
    "trainingSet.drop(['Unnamed: 0','denominacion_empresa'],axis=1,inplace=True)\n",
    "trainingSet[[\"sexo\",'nombre','estado','nombre_zona',\n",
    "             'tipo_de_trabajo','nivel_laboral',\n",
    "             'nombre_area']] = trainingSet[[\"sexo\",'nombre','estado','nombre_zona',\n",
    "                                            'tipo_de_trabajo','nivel_laboral',\n",
    "                                            'nombre_area']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Me quedo con 1.5M de registros random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet_samples = trainingSet.sample(n=2500000,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1571165\n",
       "0     928835\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet_samples['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hago Dummificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.sexo))\n",
    "\n",
    "trainingSet_samples.drop('sexo',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nombre))\n",
    "\n",
    "trainingSet_samples.drop('nombre',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.estado))\n",
    "\n",
    "trainingSet_samples.drop('estado',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nombre_zona))\n",
    "\n",
    "trainingSet_samples.drop('nombre_zona',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.tipo_de_trabajo))\n",
    "\n",
    "trainingSet_samples.drop('tipo_de_trabajo',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nivel_laboral,\n",
    "                                                             prefix=\"Nivel_laboral\"))\n",
    "\n",
    "trainingSet_samples.drop('nivel_laboral',axis=1, inplace=True)\n",
    "\n",
    "#trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nombre_area))\n",
    "# LO SAQUE PORQUE MI MAQUINA NO SE BANCA POR AHI LA DE UDS SI AUNQUE AGREGA MUCHAS COLUMAS(188)\n",
    "\n",
    "trainingSet_samples.drop('nombre_area',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[     0 278927]\n",
      " [     0 471073]]\n",
      "classification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucio/Documentos/Datos/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00    278927\n",
      "          1       0.63      1.00      0.77    471073\n",
      "\n",
      "avg / total       0.39      0.63      0.48    750000\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Accuracy is :\n",
      "471073\n",
      "Area under the curve : 0.500000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "columnas = trainingSet_samples.columns.drop(\"sepostulo\")\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(trainingSet_samples[columnas], \n",
    "                                        trainingSet_samples['sepostulo'],test_size=0.30, random_state=12)\n",
    "\n",
    "\n",
    "d_train = lgb.Dataset(xtrain, label=ytrain)\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 10\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 10\n",
    "params['is_unbalanced'] = True\n",
    "# Train and evaluate.\n",
    "clf = lgb.train(params, d_train, 100)\n",
    "y_pred = clf.predict(xtest)  #predicts\n",
    "\n",
    "print('confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, y_pred.round()))\n",
    "print('classification report')\n",
    "print(metrics.classification_report(ytest, y_pred.round()))\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy is :\")\n",
    "print(metrics.accuracy_score(ytest, y_pred.round(), normalize=False))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, y_pred.round())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
