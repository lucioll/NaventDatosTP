{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import time\n",
    "from datetime import datetime\n",
    "import scipy.spatial\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import HuberRegressor \n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'idaviso': np.dtype('uint64'), 'idpostulante': np.dtype('object'),\n",
    "                   'se_postulo': np.dtype('uint8'), 'sexo_numerico': np.dtype('uint8'),\n",
    "                   'edad': np.dtype('uint16'), 'estado_code': np.dtype('uint8'),\n",
    "                   'sexo_code': np.dtype('uint8'), 'nombre_code': np.dtype('uint8'),\n",
    "                   'nombre_area_code': np.dtype('uint8'),\n",
    "                    'denominacion_empresa_code': np.dtype('uint16'),\n",
    "                   'nivel_laboral_code': np.dtype('uint8'),\n",
    "                   'tipo_de_trabajo_code': np.dtype('uint8'),\n",
    "                   'nombre_zona_code': np.dtype('uint8')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "trainingSet = pd.read_csv('Data/trainingSet.csv',dtype=column_types)\n",
    "trainingSet.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "trainingSet.drop(columns=['sexo_numerico'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9439964 entries, 0 to 9439963\n",
      "Data columns (total 11 columns):\n",
      "idaviso                      uint64\n",
      "se_postulo                   uint8\n",
      "edad                         uint16\n",
      "estado_code                  uint8\n",
      "sexo_code                    uint8\n",
      "nombre_code                  uint8\n",
      "nombre_area_code             uint8\n",
      "denominacion_empresa_code    uint16\n",
      "nivel_laboral_code           uint8\n",
      "tipo_de_trabajo_code         uint8\n",
      "nombre_zona_code             uint8\n",
      "dtypes: uint16(2), uint64(1), uint8(8)\n",
      "memory usage: 180.1 MB\n"
     ]
    }
   ],
   "source": [
    "trainingSet.drop(columns=['idpostulante'],inplace=True) #No sirve para el algoritmo de ML\n",
    "trainingSet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'idaviso': np.dtype('uint64'), 'idpostulante': np.dtype('object'),\n",
    "                   'se_postulo': np.dtype('uint8'), 'edad': np.dtype('uint16'), \n",
    "                    'estado_code': np.dtype('uint8'),'sexo_code': np.dtype('uint8'),\n",
    "                    'nombre_code': np.dtype('uint8'),'nombre_area_code': np.dtype('uint8'),\n",
    "                    'denominacion_empresa_code': np.dtype('uint16'),\n",
    "                   'nivel_laboral_code': np.dtype('uint8'),\n",
    "                   'tipo_de_trabajo_code': np.dtype('uint8'),\n",
    "                   'nombre_zona_code': np.dtype('uint8')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "\n",
    "testingSet_imp_mean = pd.read_csv('TestingSets/testingSet_imp_mean.csv')\n",
    "testingSet_imp_mean.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      "nombre_area_code             100000 non-null float64\n",
      "denominacion_empresa_code    100000 non-null float64\n",
      "nivel_laboral_code           100000 non-null float64\n",
      "tipo_de_trabajo_code         100000 non-null float64\n",
      "nombre_zona_code             100000 non-null float64\n",
      "edad                         100000 non-null float64\n",
      "estado_code                  100000 non-null float64\n",
      "sexo_code                    100000 non-null float64\n",
      "nombre_code                  100000 non-null float64\n",
      "id                           100000 non-null int64\n",
      "idaviso                      100000 non-null int64\n",
      "idpostulante                 100000 non-null object\n",
      "dtypes: float64(9), int64(2), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "testingSet_imp_mean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'idaviso': np.dtype('uint64'), 'idpostulante': np.dtype('object'),\n",
    "                   'se_postulo': np.dtype('uint8'), 'edad': np.dtype('uint16'), \n",
    "                    'estado_code': np.dtype('uint8'),'sexo_code': np.dtype('uint8'),\n",
    "                    'nombre_code': np.dtype('uint8'),'nombre_area_code': np.dtype('uint8'),\n",
    "                    'denominacion_empresa_code': np.dtype('uint16'),\n",
    "                   'nivel_laboral_code': np.dtype('uint8'),\n",
    "                   'tipo_de_trabajo_code': np.dtype('uint8'),\n",
    "                   'nombre_zona_code': np.dtype('uint8')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "\n",
    "testingSet_imp_median = pd.read_csv('TestingSets/testingSet_imp_median.csv')\n",
    "testingSet_imp_median.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      "nombre_area_code             100000 non-null float64\n",
      "denominacion_empresa_code    100000 non-null float64\n",
      "nivel_laboral_code           100000 non-null float64\n",
      "tipo_de_trabajo_code         100000 non-null float64\n",
      "nombre_zona_code             100000 non-null float64\n",
      "edad                         100000 non-null float64\n",
      "estado_code                  100000 non-null float64\n",
      "sexo_code                    100000 non-null float64\n",
      "nombre_code                  100000 non-null float64\n",
      "id                           100000 non-null int64\n",
      "idaviso                      100000 non-null int64\n",
      "idpostulante                 100000 non-null object\n",
      "dtypes: float64(9), int64(2), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "testingSet_imp_median.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'idaviso': np.dtype('uint64'), 'idpostulante': np.dtype('object'),\n",
    "                   'se_postulo': np.dtype('uint8'), 'edad': np.dtype('uint16'), \n",
    "                    'estado_code': np.dtype('uint8'),'sexo_code': np.dtype('uint8'),\n",
    "                    'nombre_code': np.dtype('uint8'),'nombre_area_code': np.dtype('uint8'),\n",
    "                    'denominacion_empresa_code': np.dtype('uint16'),\n",
    "                   'nivel_laboral_code': np.dtype('uint8'),\n",
    "                   'tipo_de_trabajo_code': np.dtype('uint8'),\n",
    "                   'nombre_zona_code': np.dtype('uint8')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "\n",
    "testingSet_imp_most_frequent = pd.read_csv('TestingSets/testingSet_imp_most_frequent.csv')\n",
    "testingSet_imp_most_frequent.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      "nombre_area_code             100000 non-null float64\n",
      "denominacion_empresa_code    100000 non-null float64\n",
      "nivel_laboral_code           100000 non-null float64\n",
      "tipo_de_trabajo_code         100000 non-null float64\n",
      "nombre_zona_code             100000 non-null float64\n",
      "edad                         100000 non-null float64\n",
      "estado_code                  100000 non-null float64\n",
      "sexo_code                    100000 non-null float64\n",
      "nombre_code                  100000 non-null float64\n",
      "id                           100000 non-null int64\n",
      "idaviso                      100000 non-null int64\n",
      "idpostulante                 100000 non-null object\n",
      "dtypes: float64(9), int64(2), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "testingSet_imp_most_frequent.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e8d86efc3b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# evaluate each model in turn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_pruebas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumnas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset_pruebas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice_aprox_usd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision = {:.2f} % , name = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Datos/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m         X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n\u001b[1;32m    488\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             copy=self.copy_X, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Datos/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     X = check_array(X, copy=copy, accept_sparse=['csr', 'csc'],\n\u001b[0;32m--> 168\u001b[0;31m                     dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Datos/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columnas = trainingSet.columns\n",
    "\n",
    "set_entrenamiento = trainingSet.loc[:]\n",
    "set_pruebas = trainingSet\n",
    "\n",
    "array = set_entrenamiento.values\n",
    "X = array[:,0:7]\n",
    "Y = array[:,7]\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LinearRegression', LinearRegression()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('RidgeCV', RidgeCV()))\n",
    "models.append(('Lasso', Lasso()))\n",
    "models.append(('Elastic Net', ElasticNet()))\n",
    "models.append(('LassoLars', LassoLars()))\n",
    "models.append(('OrthogonalMatchingPursuit', OrthogonalMatchingPursuit()))\n",
    "models.append(('BayesianRidge', BayesianRidge()))\n",
    "models.append(('HuberRegressor  ', HuberRegressor()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "for name, model in models:\n",
    "    model.fit(X,Y)\n",
    "    score = model.score(set_pruebas.loc[:,columnas],set_pruebas.price_aprox_usd) * 100\n",
    "    print(\"Precision = {:.2f} % , name = {}\".format(score,name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
