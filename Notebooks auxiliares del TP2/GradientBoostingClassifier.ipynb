{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucio/Documentos/Datos/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/lucio/Documentos/Datos/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'sepostulo': np.dtype('uint8'),'edad': np.dtype('uint16')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "trainingSet = pd.read_csv('/home/lucio/Documentos/Datos/NaventDatosTP/Data/TRAINING_SET_SIN_ENCODING.csv',dtype=column_types)\n",
    "trainingSet.drop(['Unnamed: 0','denominacion_empresa'],axis=1,inplace=True)\n",
    "trainingSet[[\"sexo\",'nombre','estado','nombre_zona',\n",
    "             'tipo_de_trabajo','nivel_laboral',\n",
    "             'nombre_area']] = trainingSet[[\"sexo\",'nombre','estado','nombre_zona',\n",
    "                                            'tipo_de_trabajo','nivel_laboral',\n",
    "                                            'nombre_area']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9439964 entries, 0 to 9439963\n",
      "Data columns (total 9 columns):\n",
      "sepostulo          uint8\n",
      "sexo               category\n",
      "nombre             category\n",
      "estado             category\n",
      "edad               uint16\n",
      "nombre_zona        category\n",
      "tipo_de_trabajo    category\n",
      "nivel_laboral      category\n",
      "nombre_area        category\n",
      "dtypes: category(7), uint16(1), uint8(1)\n",
      "memory usage: 99.0 MB\n"
     ]
    }
   ],
   "source": [
    "trainingSet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Me quedo con 1.5M de registros random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet_samples = trainingSet.sample(n=1500000,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    942921\n",
       "0    557079\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet_samples['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hago dummificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.sexo))\n",
    "\n",
    "trainingSet_samples.drop('sexo',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nombre))\n",
    "\n",
    "trainingSet_samples.drop('nombre',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.estado))\n",
    "\n",
    "trainingSet_samples.drop('estado',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nombre_zona))\n",
    "\n",
    "trainingSet_samples.drop('nombre_zona',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.tipo_de_trabajo))\n",
    "\n",
    "trainingSet_samples.drop('tipo_de_trabajo',axis=1, inplace=True)\n",
    "\n",
    "trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nivel_laboral,\n",
    "                                                             prefix=\"Nivel_laboral\"))\n",
    "\n",
    "trainingSet_samples.drop('nivel_laboral',axis=1, inplace=True)\n",
    "\n",
    "#trainingSet_samples = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nombre_area))\n",
    "# LO SAQUE PORQUE MI MAQUINA NO SE BANCA POR AHI LA DE UDS SI AUNQUE AGREGA MUCHAS COLUMAS(188)\n",
    "\n",
    "trainingSet_samples.drop('nombre_area',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[  2056 164830]\n",
      " [  1370 281744]]\n",
      "classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.01      0.02    166886\n",
      "          1       0.63      1.00      0.77    283114\n",
      "\n",
      "avg / total       0.62      0.63      0.49    450000\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Accuracy is :\n",
      "0.6306666666666667\n",
      "Area under the curve : 0.503740\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "columnas = trainingSet_samples.columns.drop(\"sepostulo\")\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(trainingSet_samples[columnas], \n",
    "                                        trainingSet_samples['sepostulo'],test_size=0.30, random_state=12)\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 3, 'subsample': 0.5,\n",
    "          'learning_rate': 0.01, 'min_samples_leaf': 1, 'random_state': 3}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(xtrain, ytrain) #trains\n",
    "y_pred = clf.predict(xtest)  #predicts\n",
    "print('confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, y_pred))\n",
    "print('classification report')\n",
    "print(metrics.classification_report(ytest, y_pred))\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy is :\")\n",
    "print(metrics.accuracy_score(ytest, y_pred))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We are taking 10% of non frauds and merge it with frauds data'''\n",
    "\n",
    "si_sepostulo = trainingSet_samples[trainingSet_samples['sepostulo'] ==1]\n",
    "no_sepostulo = trainingSet_samples[trainingSet_samples['sepostulo'] == 0]\n",
    "\n",
    "# random sampling\n",
    "ignore_me, si_sepostulo = train_test_split(si_sepostulo, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "si_sepostulo = pd.concat([si_sepostulo, no_sepostulo])\n",
    "\n",
    "# Split into train and test units.\n",
    "xtrain, xtest = train_test_split(si_sepostulo, test_size = 0.3)\n",
    "ytrain = xtrain['sepostulo']\n",
    "ytest = xtest['sepostulo']\n",
    "xtrain.drop('sepostulo', 1, inplace = True)\n",
    "xtest.drop('sepostulo', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[167015      0]\n",
      " [ 28394      3]]\n",
      "classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92    167015\n",
      "          1       1.00      0.00      0.00     28397\n",
      "\n",
      "avg / total       0.88      0.85      0.79    195412\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Accuracy is :\n",
      "0.8546967432910978\n",
      "Area under the curve : 0.500053\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 3, 'subsample': 0.5,\n",
    "          'learning_rate': 0.01, 'min_samples_leaf': 1, 'random_state': 3}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(xtrain, ytrain) #trains\n",
    "y_pred = clf.predict(xtest)  #predicts\n",
    "print('confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, y_pred))\n",
    "print('classification report')\n",
    "print(metrics.classification_report(ytest, y_pred))\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy is :\")\n",
    "print(metrics.accuracy_score(ytest, y_pred))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hago over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "columnas = trainingSet_samples.columns.drop(\"sepostulo\")\n",
    "x_train, x_val, y_train, y_val = train_test_split(trainingSet_samples[columnas], \n",
    "                                        trainingSet_samples['sepostulo'],test_size = .1,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucio/Documentos/Datos/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "0.5353\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'recall_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-602db856bc6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Validation Results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgbm0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbm0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'recall_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "\n",
    "performCV=True\n",
    "printFeatureImportance=True\n",
    "cv_folds=5\n",
    "#Fit the algorithm on the data\n",
    "gbm0.fit(x_train_res, y_train_res)\n",
    "\n",
    "print ('Validation Results')\n",
    "print (gbm0.score(x_val, y_val))\n",
    "print (recall_score(y_val, gbm0.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3b76cc1fe566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcv_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Fit the algorithm on the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgbm0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingSet_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingSet_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sepostulo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#Predict training set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Datos/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Presorting is not supported for sparse matrices.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n\u001b[0m\u001b[1;32m   1030\u001b[0m                                                  dtype=np.int32)\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Datos/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \"\"\"\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Datos/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "target = \"sepostulo\"\n",
    "predictors = [x for x in trainingSet_samples.columns if x not in [target]]\n",
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "\n",
    "performCV=True\n",
    "printFeatureImportance=True\n",
    "cv_folds=5\n",
    "#Fit the algorithm on the data\n",
    "gbm0.fit(trainingSet_samples[predictors], trainingSet_samples['sepostulo'])\n",
    "\n",
    "#Predict training set:\n",
    "dtrain_predictions = gbm0.predict(trainingSet_samples[predictors])\n",
    "dtrain_predprob = gbm0.predict_proba(trainingSet_samples[predictors])[:,1]\n",
    "\n",
    "#Perform cross-validation:\n",
    "if performCV:\n",
    "    cv_score = cross_validation.cross_val_score(gbm0, trainingSet_samples[predictors],\n",
    "                                                trainingSet_samples['sepostulo'],\n",
    "                                                cv=cv_folds, scoring='roc_auc')\n",
    "\n",
    "#Print model report:\n",
    "print (\"\\nModel Report\")\n",
    "print (\"Accuracy : %.4g\" % metrics.accuracy_score(trainingSet_samples['sepostulo'].values,\n",
    "                                                  dtrain_predictions))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(trainingSet_samples['sepostulo'], dtrain_predprob))\n",
    "\n",
    "if performCV:\n",
    "    print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % \n",
    "           (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "\n",
    "#Print Feature Importance:\n",
    "if printFeatureImportance:\n",
    "    feat_imp = pd.Series(gbm0.feature_importances_, predictors).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'estado': CategoricalDtype(categories=['Abandonado', 'En Curso', 'Graduado'], \n",
    "                                               ordered=False), 'idpostulante': np.dtype('object'),\n",
    "                    'nombre': CategoricalDtype(categories=['Doctorado', 'Master', 'Otro', 'Posgrado',\n",
    "                            'Secundario','Terciario/Técnico', 'Universitario'],ordered=False),\n",
    "                    'sexo': CategoricalDtype(categories=['FEM', 'MASC', 'NO_DECLARA'], ordered=False)})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "testingSet_CON_NAN = pd.read_csv('/home/lucio/Documentos/Datos/NaventDatosTP/TestingSets/testingSet_CON_NAN.csv',dtype=column_types)\n",
    "testingSet_CON_NAN.drop('Unnamed: 0',inplace=True,axis=1)\n",
    "testingSet_CON_NAN.drop(columns=['idpostulante','denominacion_empresa','nombre_area'],inplace=True) #No sirve para el algoritmo de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplico dummificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingSet_CON_NAN = testingSet_CON_NAN.join(pd.get_dummies(testingSet_CON_NAN.sexo))\n",
    "\n",
    "testingSet_CON_NAN.drop('sexo',axis=1, inplace=True)\n",
    "\n",
    "testingSet_CON_NAN = testingSet_CON_NAN.join(pd.get_dummies(testingSet_CON_NAN.nombre))\n",
    "\n",
    "testingSet_CON_NAN.drop('nombre',axis=1, inplace=True)\n",
    "\n",
    "testingSet_CON_NAN = testingSet_CON_NAN.join(pd.get_dummies(testingSet_CON_NAN.estado))\n",
    "\n",
    "testingSet_CON_NAN.drop('estado',axis=1, inplace=True)\n",
    "\n",
    "testingSet_CON_NAN = testingSet_CON_NAN.join(pd.get_dummies(testingSet_CON_NAN.nombre_zona))\n",
    "\n",
    "testingSet_CON_NAN.drop('nombre_zona',axis=1, inplace=True)\n",
    "\n",
    "testingSet_CON_NAN = testingSet_CON_NAN.join(pd.get_dummies(testingSet_CON_NAN.tipo_de_trabajo))\n",
    "\n",
    "testingSet_CON_NAN.drop('tipo_de_trabajo',axis=1, inplace=True)\n",
    "\n",
    "testingSet_CON_NAN = testingSet_CON_NAN.join(pd.get_dummies(testingSet_CON_NAN.nivel_laboral,\n",
    "                                                             prefix=\"Nivel_laboral\"))\n",
    "\n",
    "testingSet_CON_NAN.drop('nivel_laboral',axis=1, inplace=True)\n",
    "\n",
    "#testingSet_CON_NAN = trainingSet_samples.join(pd.get_dummies(trainingSet_samples.nombre_area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get missing columns in the training test\n",
    "missing_cols = set( trainingSet_samples.columns ) - set( testingSet_CON_NAN.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    testingSet_CON_NAN[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "testingSet_CON_NAN = testingSet_CON_NAN[trainingSet_samples.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 42 columns):\n",
      "sepostulo                                             100000 non-null int64\n",
      "edad                                                  93375 non-null float64\n",
      "FEM                                                   100000 non-null uint8\n",
      "MASC                                                  100000 non-null uint8\n",
      "NO_DECLARA                                            100000 non-null uint8\n",
      "Doctorado                                             100000 non-null uint8\n",
      "Master                                                100000 non-null uint8\n",
      "Otro                                                  100000 non-null uint8\n",
      "Posgrado                                              100000 non-null uint8\n",
      "Secundario                                            100000 non-null uint8\n",
      "Terciario/Técnico                                     100000 non-null uint8\n",
      "Universitario                                         100000 non-null uint8\n",
      "Abandonado                                            100000 non-null uint8\n",
      "En Curso                                              100000 non-null uint8\n",
      "Graduado                                              100000 non-null uint8\n",
      "Buenos Aires (fuera de GBA)                           100000 non-null uint8\n",
      "Capital Federal                                       100000 non-null uint8\n",
      "Catamarca                                             100000 non-null uint8\n",
      "Cordoba                                               100000 non-null uint8\n",
      "Corrientes                                            100000 non-null uint8\n",
      "GBA Oeste                                             100000 non-null uint8\n",
      "Gran Buenos Aires                                     100000 non-null uint8\n",
      "La Plata                                              100000 non-null uint8\n",
      "Rosario                                               100000 non-null uint8\n",
      "San Juan                                              100000 non-null uint8\n",
      "Santa Cruz                                            100000 non-null uint8\n",
      "Tucuman                                               100000 non-null uint8\n",
      "Fines de Semana                                       100000 non-null uint8\n",
      "Full-time                                             100000 non-null uint8\n",
      "Part-time                                             100000 non-null uint8\n",
      "Pasantia                                              100000 non-null uint8\n",
      "Por Contrato                                          100000 non-null uint8\n",
      "Por Horas                                             100000 non-null uint8\n",
      "Primer empleo                                         100000 non-null uint8\n",
      "Teletrabajo                                           100000 non-null uint8\n",
      "Temporario                                            100000 non-null uint8\n",
      "Voluntario                                            100000 non-null int64\n",
      "Nivel_laboral_Gerencia / Alta Gerencia / Dirección    100000 non-null uint8\n",
      "Nivel_laboral_Jefe / Supervisor / Responsable         100000 non-null uint8\n",
      "Nivel_laboral_Junior                                  100000 non-null uint8\n",
      "Nivel_laboral_Otro                                    100000 non-null uint8\n",
      "Nivel_laboral_Senior / Semi-Senior                    100000 non-null uint8\n",
      "dtypes: float64(1), int64(2), uint8(39)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "testingSet_CON_NAN.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplico imputing a la edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 42 columns):\n",
      "sepostulo                                             100000 non-null int64\n",
      "edad                                                  100000 non-null float64\n",
      "FEM                                                   100000 non-null uint8\n",
      "MASC                                                  100000 non-null uint8\n",
      "NO_DECLARA                                            100000 non-null uint8\n",
      "Doctorado                                             100000 non-null uint8\n",
      "Master                                                100000 non-null uint8\n",
      "Otro                                                  100000 non-null uint8\n",
      "Posgrado                                              100000 non-null uint8\n",
      "Secundario                                            100000 non-null uint8\n",
      "Terciario/Técnico                                     100000 non-null uint8\n",
      "Universitario                                         100000 non-null uint8\n",
      "Abandonado                                            100000 non-null uint8\n",
      "En Curso                                              100000 non-null uint8\n",
      "Graduado                                              100000 non-null uint8\n",
      "Buenos Aires (fuera de GBA)                           100000 non-null uint8\n",
      "Capital Federal                                       100000 non-null uint8\n",
      "Catamarca                                             100000 non-null uint8\n",
      "Cordoba                                               100000 non-null uint8\n",
      "Corrientes                                            100000 non-null uint8\n",
      "GBA Oeste                                             100000 non-null uint8\n",
      "Gran Buenos Aires                                     100000 non-null uint8\n",
      "La Plata                                              100000 non-null uint8\n",
      "Rosario                                               100000 non-null uint8\n",
      "San Juan                                              100000 non-null uint8\n",
      "Santa Cruz                                            100000 non-null uint8\n",
      "Tucuman                                               100000 non-null uint8\n",
      "Fines de Semana                                       100000 non-null uint8\n",
      "Full-time                                             100000 non-null uint8\n",
      "Part-time                                             100000 non-null uint8\n",
      "Pasantia                                              100000 non-null uint8\n",
      "Por Contrato                                          100000 non-null uint8\n",
      "Por Horas                                             100000 non-null uint8\n",
      "Primer empleo                                         100000 non-null uint8\n",
      "Teletrabajo                                           100000 non-null uint8\n",
      "Temporario                                            100000 non-null uint8\n",
      "Voluntario                                            100000 non-null int64\n",
      "Nivel_laboral_Gerencia / Alta Gerencia / Dirección    100000 non-null uint8\n",
      "Nivel_laboral_Jefe / Supervisor / Responsable         100000 non-null uint8\n",
      "Nivel_laboral_Junior                                  100000 non-null uint8\n",
      "Nivel_laboral_Otro                                    100000 non-null uint8\n",
      "Nivel_laboral_Senior / Semi-Senior                    100000 non-null uint8\n",
      "dtypes: float64(1), int64(2), uint8(39)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "testingSet_CON_NAN['edad'].fillna(testingSet_CON_NAN['edad'].mode()[0],inplace=True)\n",
    "testingSet_CON_NAN.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict testing set:\n",
    "dtest_predictions = clf.predict(testingSet_CON_NAN[columnas])\n",
    "dtest_predprob = clf.predict_proba(testingSet_CON_NAN[columnas])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingSet_CON_NAN['sepostulo'] = dtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    98809\n",
       "0     1191\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingSet_CON_NAN['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    51432\n",
       "1    48568\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingSet_CON_NAN['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100000\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingSet_CON_NAN['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepostulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepostulo\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = testingSet_CON_NAN[['sepostulo']]\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero volver a leer el testingSet del csv\n",
    "submit.insert(0, 'id', testingSet_CON_NAN['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('Submit/prediccion29_LIGHTGBM_1.5M_dummies_over_sampling.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
