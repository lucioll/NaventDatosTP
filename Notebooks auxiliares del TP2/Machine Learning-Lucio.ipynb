{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import time\n",
    "from datetime import datetime\n",
    "import scipy.spatial\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import HuberRegressor \n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'idaviso': np.dtype('uint64'), 'idpostulante': np.dtype('object'),\n",
    "                   'se_postulo': np.dtype('uint8'), 'sexo_numerico': np.dtype('uint8'),\n",
    "                   'edad': np.dtype('uint16'), 'estado_code': np.dtype('uint8'),\n",
    "                   'sexo_code': np.dtype('uint8'), 'nombre_code': np.dtype('uint8'),\n",
    "                   'nombre_area_code': np.dtype('uint8'),\n",
    "                    'denominacion_empresa_code': np.dtype('uint16'),\n",
    "                   'nivel_laboral_code': np.dtype('uint8'),\n",
    "                   'tipo_de_trabajo_code': np.dtype('uint8'),\n",
    "                   'nombre_zona_code': np.dtype('uint8')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "trainingSet = pd.read_csv('Data/trainingSet.csv',dtype=column_types)\n",
    "trainingSet.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "trainingSet.drop(columns=['sexo_numerico'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9439964 entries, 0 to 9439963\n",
      "Data columns (total 12 columns):\n",
      "idaviso                      uint64\n",
      "idpostulante                 object\n",
      "se_postulo                   uint8\n",
      "edad                         uint16\n",
      "estado_code                  uint8\n",
      "sexo_code                    uint8\n",
      "nombre_code                  uint8\n",
      "nombre_area_code             uint8\n",
      "denominacion_empresa_code    uint16\n",
      "nivel_laboral_code           uint8\n",
      "tipo_de_trabajo_code         uint8\n",
      "nombre_zona_code             uint8\n",
      "dtypes: object(1), uint16(2), uint64(1), uint8(8)\n",
      "memory usage: 252.1+ MB\n"
     ]
    }
   ],
   "source": [
    "trainingSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a codificar la columna de idpostulantes\n",
    "lb_make1 = LabelEncoder()\n",
    "trainingSet[\"idpostulante_code\"] = lb_make1.fit_transform(trainingSet[\"idpostulante\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet.drop(columns=['idpostulante'],inplace=True) #No sirve para el algoritmo de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'idaviso': np.dtype('uint64'), 'idpostulante': np.dtype('object'),\n",
    "                   'se_postulo': np.dtype('uint8'), 'edad': np.dtype('uint16'), \n",
    "                    'estado_code': np.dtype('uint8'),'sexo_code': np.dtype('uint8'),\n",
    "                    'nombre_code': np.dtype('uint8'),'nombre_area_code': np.dtype('uint8'),\n",
    "                    'denominacion_empresa_code': np.dtype('uint16'),\n",
    "                   'nivel_laboral_code': np.dtype('uint8'),\n",
    "                   'tipo_de_trabajo_code': np.dtype('uint8'),\n",
    "                   'nombre_zona_code': np.dtype('uint8')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "\n",
    "testingSet_imp_mean = pd.read_csv('TestingSets/testingSet_imp_mean.csv')\n",
    "testingSet_imp_mean.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      "nombre_area_code             100000 non-null float64\n",
      "denominacion_empresa_code    100000 non-null float64\n",
      "nivel_laboral_code           100000 non-null float64\n",
      "tipo_de_trabajo_code         100000 non-null float64\n",
      "nombre_zona_code             100000 non-null float64\n",
      "edad                         100000 non-null float64\n",
      "estado_code                  100000 non-null float64\n",
      "sexo_code                    100000 non-null float64\n",
      "nombre_code                  100000 non-null float64\n",
      "id                           100000 non-null int64\n",
      "idaviso                      100000 non-null int64\n",
      "idpostulante                 100000 non-null object\n",
      "dtypes: float64(9), int64(2), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "testingSet_imp_mean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'idaviso': np.dtype('uint64'), 'idpostulante': np.dtype('object'),\n",
    "                   'se_postulo': np.dtype('uint8'), 'edad': np.dtype('uint16'), \n",
    "                    'estado_code': np.dtype('uint8'),'sexo_code': np.dtype('uint8'),\n",
    "                    'nombre_code': np.dtype('uint8'),'nombre_area_code': np.dtype('uint8'),\n",
    "                    'denominacion_empresa_code': np.dtype('uint16'),\n",
    "                   'nivel_laboral_code': np.dtype('uint8'),\n",
    "                   'tipo_de_trabajo_code': np.dtype('uint8'),\n",
    "                   'nombre_zona_code': np.dtype('uint8')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "\n",
    "testingSet_imp_median = pd.read_csv('TestingSets/testingSet_imp_median.csv')\n",
    "testingSet_imp_median.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      "nombre_area_code             100000 non-null float64\n",
      "denominacion_empresa_code    100000 non-null float64\n",
      "nivel_laboral_code           100000 non-null float64\n",
      "tipo_de_trabajo_code         100000 non-null float64\n",
      "nombre_zona_code             100000 non-null float64\n",
      "edad                         100000 non-null float64\n",
      "estado_code                  100000 non-null float64\n",
      "sexo_code                    100000 non-null float64\n",
      "nombre_code                  100000 non-null float64\n",
      "id                           100000 non-null int64\n",
      "idaviso                      100000 non-null int64\n",
      "idpostulante                 100000 non-null object\n",
      "dtypes: float64(9), int64(2), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "testingSet_imp_median.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.Series({'idaviso': np.dtype('uint64'), 'idpostulante': np.dtype('object'),\n",
    "                   'se_postulo': np.dtype('uint8'), 'edad': np.dtype('uint16'), \n",
    "                    'estado_code': np.dtype('uint8'),'sexo_code': np.dtype('uint8'),\n",
    "                    'nombre_code': np.dtype('uint8'),'nombre_area_code': np.dtype('uint8'),\n",
    "                    'denominacion_empresa_code': np.dtype('uint16'),\n",
    "                   'nivel_laboral_code': np.dtype('uint8'),\n",
    "                   'tipo_de_trabajo_code': np.dtype('uint8'),\n",
    "                   'nombre_zona_code': np.dtype('uint8')})\n",
    "\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "\n",
    "\n",
    "testingSet_imp_most_frequent = pd.read_csv('TestingSets/testingSet_imp_most_frequent.csv')\n",
    "testingSet_imp_most_frequent.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      "nombre_area_code             100000 non-null float64\n",
      "denominacion_empresa_code    100000 non-null float64\n",
      "nivel_laboral_code           100000 non-null float64\n",
      "tipo_de_trabajo_code         100000 non-null float64\n",
      "nombre_zona_code             100000 non-null float64\n",
      "edad                         100000 non-null float64\n",
      "estado_code                  100000 non-null float64\n",
      "sexo_code                    100000 non-null float64\n",
      "nombre_code                  100000 non-null float64\n",
      "id                           100000 non-null int64\n",
      "idaviso                      100000 non-null int64\n",
      "idpostulante                 100000 non-null object\n",
      "dtypes: float64(9), int64(2), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "testingSet_imp_most_frequent.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.35 % , name = LinearRegression\n",
      "Precision = 0.35 % , name = Ridge\n",
      "Precision = -78121918887.95 % , name = RidgeCV\n",
      "Precision = 0.02 % , name = Lasso\n",
      "Precision = 0.02 % , name = Elastic Net\n",
      "Precision = 0.00 % , name = LassoLars\n",
      "Precision = 0.19 % , name = OrthogonalMatchingPursuit\n",
      "Precision = 0.35 % , name = BayesianRidge\n",
      "Precision = -0.04 % , name = HuberRegressor  \n"
     ]
    }
   ],
   "source": [
    "columnas = ['idaviso','idpostulante_code','edad', 'estado_code', 'sexo_code',\n",
    "       'nombre_code', 'nombre_area_code', 'denominacion_empresa_code',\n",
    "       'nivel_laboral_code', 'tipo_de_trabajo_code', 'nombre_zona_code']\n",
    "\n",
    "set_pruebas = trainingSet\n",
    "\n",
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas]\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LinearRegression', LinearRegression()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('RidgeCV', RidgeCV()))\n",
    "models.append(('Lasso', Lasso()))\n",
    "models.append(('Elastic Net', ElasticNet()))\n",
    "models.append(('LassoLars', LassoLars()))\n",
    "models.append(('OrthogonalMatchingPursuit', OrthogonalMatchingPursuit()))\n",
    "models.append(('BayesianRidge', BayesianRidge()))\n",
    "models.append(('HuberRegressor  ', HuberRegressor()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "for name, model in models:\n",
    "    model.fit(X,y)\n",
    "    score = model.score(X,y) * 100\n",
    "    print(\"Precision = {:.2f} % , name = {}\".format(score,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "se_postulo                   1.000000\n",
       "sexo_code                    0.043731\n",
       "nivel_laboral_code           0.024677\n",
       "estado_code                  0.016165\n",
       "nombre_zona_code             0.010822\n",
       "idpostulante_code            0.003469\n",
       "idaviso                      0.002977\n",
       "nombre_area_code             0.002570\n",
       "tipo_de_trabajo_code        -0.007484\n",
       "edad                        -0.012981\n",
       "denominacion_empresa_code   -0.014913\n",
       "nombre_code                 -0.020866\n",
       "Name: se_postulo, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet.corr().se_postulo.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.28 % , name = LinearRegression\n",
      "Precision = 0.28 % , name = Ridge\n",
      "Precision = -210668018185.80 % , name = RidgeCV\n",
      "Precision = 0.00 % , name = Lasso\n",
      "Precision = 0.00 % , name = Elastic Net\n",
      "Precision = 0.00 % , name = LassoLars\n",
      "Precision = 0.19 % , name = OrthogonalMatchingPursuit\n",
      "Precision = 0.28 % , name = BayesianRidge\n",
      "Precision = -0.04 % , name = HuberRegressor  \n"
     ]
    }
   ],
   "source": [
    "columnas_corr = ['sexo_code','nivel_laboral_code','estado_code','nombre_zona_code','idpostulante_code',\n",
    "                 'idaviso','nombre_area_code']\n",
    "\n",
    "set_pruebas = trainingSet\n",
    "\n",
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas_corr]\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LinearRegression', LinearRegression()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('RidgeCV', RidgeCV()))\n",
    "models.append(('Lasso', Lasso()))\n",
    "models.append(('Elastic Net', ElasticNet()))\n",
    "models.append(('LassoLars', LassoLars()))\n",
    "models.append(('OrthogonalMatchingPursuit', OrthogonalMatchingPursuit()))\n",
    "models.append(('BayesianRidge', BayesianRidge()))\n",
    "models.append(('HuberRegressor  ', HuberRegressor()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "for name, model in models:\n",
    "    model.fit(X,y)\n",
    "    score = model.score(X,y) * 100\n",
    "    print(\"Precision = {:.2f} % , name = {}\".format(score,name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method name = RandomForestRegressor\n",
      "Mean squared error: 0.19485293319871383\n",
      "Precission: 88.25 %\n"
     ]
    }
   ],
   "source": [
    "columnas = ['idaviso','idpostulante_code','edad', 'estado_code', 'sexo_code',\n",
    "       'nombre_code', 'nombre_area_code', 'denominacion_empresa_code',\n",
    "       'nivel_laboral_code', 'tipo_de_trabajo_code', 'nombre_zona_code']\n",
    "\n",
    "set_pruebas = trainingSet\n",
    "\n",
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas]\n",
    "\n",
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(X,y)\n",
    "precission = random_forest.score(X,y) * 100\n",
    "mse = np.mean(cross_val_score(random_forest, X, y,scoring='neg_mean_squared_error', cv=15,  n_jobs=2))\n",
    "print(\"Method name = {}\".format(\"RandomForestRegressor\"))\n",
    "print ('Mean squared error: {}'.format(abs(mse)))\n",
    "print ('Precission: {:.2f} %'. format(abs(precission)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabrizio/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method name = ExtraTreesRegressor\n",
      "Mean squared error: 0.2334869833774863\n",
      "Precission: 1.474309678783925e-05 %\n"
     ]
    }
   ],
   "source": [
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "extra_tree = ExtraTreesRegressor(n_estimators=32, criterion = 'mse', max_depth=None, min_samples_split=5,\\\n",
    "                                 min_samples_leaf=1, min_weight_fraction_leaf = 0.0, max_features =\"auto\",\\\n",
    "                                max_leaf_nodes = None,min_impurity_decrease = 6,bootstrap = False)\n",
    "extra_tree.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "precission = extra_tree.score(X_test,y_test) * 100\n",
    "mse = np.mean(cross_val_score(extra_tree, X_test, y_test,scoring='neg_mean_squared_error', cv=15,  n_jobs=2))\n",
    "print(\"Method name = {}\".format(\"ExtraTreesRegressor\"))\n",
    "print ('Mean squared error: {}'.format(abs(mse)))\n",
    "print ('Precission: {} %'. format(abs(precission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method name = GradientBoostingRegressor\n",
      "Mean squared error: 0.2556160523924702\n",
      "Precission: 37.677365878911914 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "gradient_boosting = GradientBoostingRegressor(loss='ls', learning_rate=0.75, n_estimators=100, subsample=1.0, criterion='mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "gradient_boosting.fit(X,y)\n",
    "\n",
    "precission = gradient_boosting.score(X,y) * 100\n",
    "mse = np.mean(cross_val_score(gradient_boosting, X, y,scoring='neg_mean_squared_error', cv=5,  n_jobs=2))\n",
    "print(\"Method name = {}\".format(\"GradientBoostingRegressor\"))\n",
    "print ('Mean squared error: {}'.format(abs(mse)))\n",
    "print ('Precission: {} %'. format(abs(precission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-78eff73ae3f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mada_boost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mprecission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mada_boost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_boost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method name = {}, Estimator = {}, Loss = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AdaBoostRegressor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    387\u001b[0m                         multioutput='variance_weighted')\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_median_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_get_median_predict\u001b[0;34m(self, X, limit)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;31m# Find index of median prediction for each sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m         \u001b[0mweight_cdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstable_cumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_weights_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m         \u001b[0mmedian_or_above\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_cdf\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_cdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mmedian_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedian_or_above\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mstable_cumsum\u001b[0;34m(arr, axis, rtol, atol)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     if not np.all(np.isclose(out.take(-1, axis=axis), expected, rtol=rtol,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m     \"\"\"\n\u001b[0;32m-> 2165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cumsum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "columnas = ['idaviso','idpostulante_code','edad', 'estado_code', 'sexo_code',\n",
    "       'nombre_code', 'nombre_area_code', 'denominacion_empresa_code',\n",
    "       'nivel_laboral_code', 'tipo_de_trabajo_code', 'nombre_zona_code']\n",
    "\n",
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "#Tambien probar con columnas corr\n",
    "\n",
    "\n",
    "for estimator in [DecisionTreeRegressor(),RandomForestRegressor(),ExtraTreesRegressor(),GradientBoostingRegressor()]:\n",
    "    for val_loss in ['linear','square','exponential']:\n",
    "        ada_boost= AdaBoostRegressor(loss=val_loss,base_estimator=estimator)\n",
    "        ada_boost.fit(X,y)\n",
    "\n",
    "        precission = ada_boost.score(X,y) * 100\n",
    "        mse = np.mean(cross_val_score(ada_boost, X, y,scoring='neg_mean_squared_error', cv=15,  n_jobs=2))\n",
    "        print(\"Method name = {}, Estimator = {}, Loss = {}\".format(\"AdaBoostRegressor\",estimator,val_loss))\n",
    "        print ('Mean squared error: {}'.format(abs(mse)))\n",
    "        print ('Precission: {} %'. format(abs(precission)))\n",
    "        print (\"\")\n",
    "        print (\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting... Inicio: 14:07:46 \n",
      "RandomizedSearchCV took 2266.89 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: -59.384 (std: 1.188)\n",
      "Parameters: {'n_estimators': 25, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 0.4, 'max_depth': 10, 'criterion': 'friedman_mse', 'bootstrap': False}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -59.776 (std: 1.196)\n",
      "Parameters: {'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.8, 'max_depth': 5, 'criterion': 'mse', 'bootstrap': False}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -59.789 (std: 1.196)\n",
      "Parameters: {'n_estimators': 80, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 0.8, 'max_depth': 3, 'criterion': 'mse', 'bootstrap': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "#Tambien probar con columnas corr\n",
    "\n",
    "\n",
    "extra = ExtraTreesRegressor()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  (results['mean_test_score'][candidate])*100,\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None,5,10,1],\n",
    "              \"max_features\": [0.2,0.4,0.6,0.8,1.0],\n",
    "              \"n_estimators\" : [10,25,50,80,100],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [2, 3, 10],\n",
    "              \"criterion\": [\"mse\",\"friedman_mse\"],\n",
    "              \"bootstrap\": [True, False]}\n",
    "\n",
    "# run randomized search\n",
    "random_search = RandomizedSearchCV(estimator = extra, param_distributions=param_dist, n_jobs = 2, cv = 5)\n",
    "\n",
    "start = time.time()\n",
    "print (\"Fitting... Inicio: {} \".format(time.strftime(\"%X\")))\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\" % ((time.time() - start), len(random_search.cv_results_['params'])))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting... Inicio: 20:51:21 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5a1bd89a81a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting... Inicio: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%X\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "columnas = ['idaviso','idpostulante_code','edad', 'estado_code', 'sexo_code',\n",
    "       'nombre_code', 'nombre_area_code', 'denominacion_empresa_code',\n",
    "       'nivel_laboral_code', 'tipo_de_trabajo_code', 'nombre_zona_code']\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  (results['mean_test_score'][candidate])*100,\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None,5,10,1],\n",
    "              \"max_features\": [0.2,0.4,0.6,0.8,1.0],\n",
    "              \"splitter\" : [\"random\",\"best\"],\n",
    "              \"min_samples_split\": [2, 3],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"criterion\": [\"mse\",\"friedman_mse\"]}\n",
    "\n",
    "X,y = trainingSet,trainingSet.se_postulo\n",
    "X = X[columnas]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "#Tambien probar con columnas corr\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(estimator = tree, param_grid=param_grid,n_jobs= 2,cv = 15)\n",
    "start = time.time()\n",
    "print (\"Fitting... Inicio: {} \".format(time.strftime(\"%X\")))\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time.time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
